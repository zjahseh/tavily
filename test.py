# ğŸ“¦ è‡ªå‹•æ–°èæ•´åˆç³»çµ± v1.2
# åŠŸèƒ½ï¼šæ•´åˆ Google Custom Search + Tavily æœå°‹ + Gemini æ‘˜è¦ â†’ ç”Ÿæˆå°ç£æ¯æ—¥æ–°èç¶œåˆå ±å‘Š (åŒ…å«åƒè€ƒé€£çµ)

import os
from dotenv import load_dotenv
from tavily import TavilyClient
import google.generativeai as genai
import pandas as pd
import time
from google.generativeai import types
from googleapiclient.discovery import build

# ==========================
# åˆå§‹åŒ–ç’°å¢ƒè®Šæ•¸
# ==========================
load_dotenv()
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")  # ä½ çš„ API Key
CSE_ID = os.getenv("GOOGLE_CSE_ID")  # Google Custom Search Engine ID

if not TAVILY_API_KEY or not GOOGLE_API_KEY or not CSE_ID:
    raise ValueError("âŒ è«‹ç¢ºèªå·²åœ¨ .env æª”ä¸­è¨­å®š TAVILY_API_KEYã€GOOGLE_API_KEY èˆ‡ GOOGLE_CSE_ID")

# åˆå§‹åŒ–å®¢æˆ¶ç«¯
tavily_client = TavilyClient(api_key=TAVILY_API_KEY)
genai.configure(api_key=GOOGLE_API_KEY)
gemini_model = genai.GenerativeModel("models/gemini-2.5-flash")

# åˆå§‹åŒ– Google Custom Search
search_service = build("customsearch", "v1", developerKey=GOOGLE_API_KEY)


# ==========================
# Phase 0ï¼šGoogle News æ¨™é¡Œæå– (API ç‰ˆ)
# ==========================
def get_google_news_headlines(max_results=15, query="å°ç£æ–°è"):
    """
    ä½¿ç”¨ Google Custom Search API å–å¾—æ–°èæ¨™é¡Œ
    """
    print("ğŸ“° [Phase 0] é€é Google Custom Search API ç²å–æ–°èæ¨™é¡Œ...")

    headlines = []
    try:
        # é™åˆ¶ API å‘¼å«ä¸€æ¬¡æœ€å¤š 10 ç­†
        res = search_service.cse().list(
            q=query,
            cx=CSE_ID,
            num=min(max_results, 10),
            lr='lang_zh'
        ).execute()

        for item in res.get("items", []):
            headlines.append(item.get("title"))

        if headlines:
            print(f"âœ… æˆåŠŸç²å– {len(headlines)} å€‹ Google News æ¨™é¡Œ")
            return headlines
        else:
            print("âš ï¸ API å›å‚³å…§å®¹ç‚ºç©ºï¼Œä½¿ç”¨éœæ…‹å‚™æ´")
            return ["å°ç£", "åœ‹éš›", "ç•¶åœ°", "å•†æ¥­", "ç§‘å­¸èˆ‡ç§‘æŠ€", "å¨›æ¨‚", "é«”è‚²", "å¥åº·"

                    ]

    except Exception as e:
        print(f"âŒ Google API ç™¼ç”ŸéŒ¯èª¤: {e}")
        return ["å°ç£", "åœ‹éš›", "ç•¶åœ°", "å•†æ¥­", "ç§‘å­¸èˆ‡ç§‘æŠ€", "å¨›æ¨‚", "é«”è‚²", "å¥åº·"
                ]


# ==========================
# Phase 1ï¼šæ¢ç´¢äº‹ä»¶ (ä½¿ç”¨ Google News æ¨™é¡Œ)
# ==========================
def get_main_events(query="ä»Šæ—¥æ–°è"):
    news_titles = get_google_news_headlines(max_results=15, query=query)

    sub_queries = news_titles
    print(f"ğŸ” [Phase 1] æœå°‹ (ä½¿ç”¨ {len(news_titles)} å€‹ Google News æ¨™é¡Œ) ä¸­...")

    all_articles = []
    for sub_query in sub_queries:
        try:
            # ç²å–æ–°è raw content
            response = tavily_client.search(
                query=sub_query,
                max_results=15,
                include_raw_content=True,
                time_range="day"
            )
            all_articles.extend(response["results"])
        except Exception as e:
            print(f"âš ï¸ å­æŸ¥è©¢å¤±æ•— ({sub_query})ï¼š{e}")

    context = ""
    for a in all_articles:
        raw_content = a.get('raw_content') or ''
        context += f"ä¾†æº: {a.get('url', 'ç„¡')}\næ¨™é¡Œ: {a.get('title', 'ç„¡')}\nå…§å®¹: {raw_content[:1000]}\n\n---\n\n"

    prompt = f"""
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­æ–°èç·¨è¼¯ã€‚
    æ ¹æ“šæ‰€æœ‰æ–°èï¼Œè«‹å¹«æˆ‘æç…‰å‡º 3â€“5 å€‹ã€Œç†±é–€äº‹ä»¶ã€ï¼Œ
    æ¯å€‹ä¸»é¡Œä»¥ä¸€å¥ç°¡çŸ­æ–‡å­—è¡¨ç¤ºã€‚
    --- é–‹å§‹æ–°èè³‡æ–™ ---
    {context}
    --- çµæŸæ–°èè³‡æ–™ ---
    """
    response = gemini_model.generate_content(prompt)
    print("âœ… ä¸»é¡Œæå–å®Œæˆ\n")
    # å°‡çµæœæ¸…ç†ä¸¦è½‰æ›ç‚ºåˆ—è¡¨
    return [e.strip("â€¢").strip() for e in response.text.split("\n") if e.strip()]


# ==========================
# Phase 2ï¼šæ·±åº¦æœå°‹ (å–å¾—æ–‡ç« å…§å®¹èˆ‡é€£çµ)
# ==========================
def get_event_articles(event):
    print(f"ğŸ“° [Phase 2] æ·±åº¦æœå°‹ï¼š{event}")
    all_articles = []

    try:
        # é‡å°å–®ä¸€äº‹ä»¶é€²è¡Œæ·±åº¦æœå°‹ï¼ŒåŒæ¨£è¦æ±‚ raw content
        res = tavily_client.search(query=event, max_results=15, include_raw_content=True, time_range="day")
        for r in res["results"]:
            raw_content = r.get("raw_content") or ""
            url_parts = r.get("url", "ç„¡ç¶²å€").split("/")
            source = url_parts[2] if len(url_parts) > 2 else "æœªçŸ¥ä¾†æº"
            if raw_content:
                all_articles.append({
                    "source": source,
                    "title": r.get("title", "ç„¡æ¨™é¡Œ"),
                    "url": r.get("url", "ç„¡ç¶²å€"),
                    "content": raw_content
                })
        return all_articles

    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•å–å¾— {event} çš„æ·±åº¦æœå°‹å…§å®¹ï¼š{e}")
        return []


# ==========================
# Phase 3ï¼šæ‘˜è¦æ•´åˆ (å›å‚³æ‘˜è¦èˆ‡ä½¿ç”¨çš„é€£çµ)
# ==========================
def summarize_event(event, articles):
    print(f"ğŸ§  [Phase 3] æ‘˜è¦æ•´åˆï¼š{event}")
    if not articles:
        return f"âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°é—œæ–¼ã€Œ{event}ã€çš„æœ‰æ•ˆæ–°èæ–‡ç« ï¼Œç„¡æ³•ç”Ÿæˆæ‘˜è¦ã€‚", []  # å›å‚³ç©ºçš„é€£çµåˆ—è¡¨

    context = ""
    for art in articles:
        content_text = art.get('content') or ""
        source_text = art.get('source', 'æœªçŸ¥ä¾†æº')
        title_text = art.get('title', 'ç„¡æ¨™é¡Œ')
        # åƒ…ä½¿ç”¨æ–‡ç« å‰ 750 å­—ä½œç‚ºæ‘˜è¦ Context
        context += f"ä¾†æº: {source_text}\næ¨™é¡Œ: {title_text}\nå…§å®¹: {content_text[:750]}\n\n"

    prompt = f"""
    ä»¥ä¸‹æ˜¯é—œæ–¼ã€Œ{event}ã€çš„å¤šå®¶æ–°èå ±å°ã€‚
    è«‹å¹«æˆ‘ç¶œåˆé€™äº›å…§å®¹ï¼Œæ’°å¯«ç´„ 500 å­—çš„å®¢è§€æ‘˜è¦ï¼Œ
    éœ€åŒ…å«ä¸»è¦äº‹å¯¦èˆ‡å„åª’é«”çš„ä¸åŒè§€é»ã€‚

    --- å ±å°è³‡æ–™ ---
    {context}
    --- çµæŸ ---
    """
    response = gemini_model.generate_content(prompt)

    # æ”¶é›†ç”¨æ–¼æœ¬æ¬¡æ‘˜è¦çš„æ‰€æœ‰ä¾†æºé€£çµå’Œè³‡è¨Š
    source_links = []
    for art in articles:
        source_links.append({
            "title": art.get('title', 'ç„¡æ¨™é¡Œ'),
            "url": art.get('url', 'ç„¡ç¶²å€'),
            "source": art.get('source', 'æœªçŸ¥ä¾†æº')
        })

    # å›å‚³æ‘˜è¦æ–‡å­—å’Œä¾†æºé€£çµåˆ—è¡¨
    return response.text, source_links


# ==========================
# Phase 4ï¼šç”Ÿæˆæ–°èå ±å‘Š (é¡¯ç¤ºæ‘˜è¦èˆ‡é€£çµ)
# ==========================
def generate_news_report():
    main_events = get_main_events()
    report = {}

    for event in main_events[:5]:
        articles = get_event_articles(event)
        if not articles:
            continue
        # æ¥æ”¶ summarize_event å›å‚³çš„æ‘˜è¦å’Œé€£çµ
        summary, sources = summarize_event(event, articles)

        # å°‡çµæœå­˜å…¥ report å­—å…¸
        report[event] = {
            "summary": summary,
            "sources": sources
        }

    print("\n==================== ğŸ—ï¸ ä»Šæ—¥ç¶œåˆæ–°èæ‘˜è¦ ====================")
    for topic, data in report.items():
        print(f"\nğŸŸ¦ {topic}")
        print(f"{data['summary']}")

        # è™•ç†ä¸¦é¡¯ç¤ºåƒè€ƒé€£çµ
        print("\nğŸ”— åƒè€ƒé€£çµ:")
        # ä½¿ç”¨ set ä¾†ç¢ºä¿é€£çµä¸é‡è¤‡ (å› ç‚º Tavily å¯èƒ½å›å‚³é‡è¤‡çš„æ–‡ç« )
        unique_urls = set()

        for src in data['sources']:
            if src['url'] not in unique_urls:
                print(f"   - [{src['source']}] {src['title']} ({src['url']})")
                unique_urls.add(src['url'])

        print(f"\n{'-' * 60}")
    print("==============================================================")


# ==========================
# ä¸»ç¨‹å¼å…¥å£
# ==========================
if __name__ == "__main__":
    generate_news_report()